# AutoSpanishBlog - Base Configuration

environment: base

# Sources for topic discovery and content fetching
sources:
  max_headlines_per_source: 20
  fetch_timeout: 10
  max_words_per_source: 300   # Truncate articles to this word count
  min_words_per_source: 100   # Minimum words for valid article
  max_sources_per_topic: 5    # Maximum sources to fetch per topic

# Topic discovery settings
discovery:
  min_sources: 3          # Minimum sources for topic validation
  max_topics: 15          # Total topics to discover
  output_limit: 10        # Topics to return to pipeline

# Topic ranking algorithm
ranking:
  source_weight: 3        # Multiplier for source count
  mention_weight: 2       # Multiplier for mention count
  mention_cap: 10         # Cap mentions at this value for scoring
  cultural_bonus: 5       # Bonus for learner-friendly topics
  avoid_penalty: -10      # Penalty for inappropriate topics

# Entity extraction settings
entity_extraction:
  min_entity_length: 2    # Minimum characters for entity
  entity_types:           # SpaCy entity types to extract
    - PER                 # Person
    - LOC                 # Location
    - ORG                 # Organization
    - MISC                # Miscellaneous

# Article generation settings
generation:
  articles_per_run: 4
  levels:
    - A2
    - B1
  target_word_count:
    A2: 200
    B1: 300

  # Two-step synthesis settings
  two_step_synthesis:
    enabled: true                    # Toggle for two-step vs single-step generation
    save_base_article: false         # Save intermediate base articles for debugging
    base_article_path: ./output/base_articles/  # Where to save base articles
    regeneration_strategy: adaptation_only  # 'adaptation_only' or 'full_pipeline'

# Quality gate settings
quality_gate:
  min_score: 7.5
  max_attempts: 3

# LLM configuration
llm:
  provider: openai  # or 'anthropic'
  models:
    generation: gpt-4o        # For synthesis (Step 1)
    adaptation: gpt-4o        # For level adaptation (Step 2) - can use cheaper model
    quality_check: gpt-4o-mini
  temperature: 0.3
  max_tokens: 4096

# Output settings
output:
  format: jekyll
  path: ./output/_posts

# Logging (overridden per environment)
logging:
  level: INFO
  format: json
  file: output/logs/app.log

# Metrics
metrics:
  enabled: true
  output: output/metrics/

# Alerts
alerts:
  enabled: false
  email: your@email.com
